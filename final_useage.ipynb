{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.utlis as vutils\n",
    "from torch.utils.data import Dataloader\n",
    "from data_util import text2ImageDataset\n",
    "from utils import process_caption, weights_init\n",
    "from text2image import Generator, Discriminator\n",
    "import os\n",
    "import time\n",
    "import imageio\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using the Device which is \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%y%m%d\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_save_path = './generated_images/'\n",
    "os.makedirs(output_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './saved_models/'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters\n",
    "noise_dimension = 100\n",
    "embed_dimension = 1024\n",
    "embed_out_dimension = 128\n",
    "batch_size = 256\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "learning_rate =0.0002\n",
    "l1_coefficient = 50\n",
    "l2_coefficient = 100\n",
    "num_of_epochs =250\n",
    "log_interval = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranin_dataset = text2ImageDataset('', split=0)\n",
    "train_loader = Dataloader(tranin_dataset, batch_size = batch_size, shuffle=True, num_workers = 8)\n",
    "print(\"Number of Batches: \", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functions\n",
    "criterion = nn.BCELoss()\n",
    "l2_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "#storee losses list\n",
    "D_losses = []\n",
    "G_losses =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing Generator\n",
    "generator = Generator(channels=3, embed_dimension= embed_dimension, noise_dimension=noise_dimension, embed_output_dimension=embed_out_dimension).to(device)\n",
    "generator.aaply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Discriminator\n",
    "discriminator = Discriminator(channels=3, embed_dimension=embed_dimension, embed_output_dimension=embed_out_dimension).to(device)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n",
    "optimizer_discriminarator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas = (0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "for epoch in range(num_of_epochs):\n",
    "    batch_time = time.time()\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        images =batch['correct_images'].to(device)\n",
    "        wrong_images = batch['wrong_images'].to(device)\n",
    "        embeddings =batch['correct_embed'].to(device)\n",
    "        batch_size = images.size(0)\n",
    "        optimizer_discriminarator.zero_grad()\n",
    "        noise = torch.randn(batch_size, noise_dimension, 1,1, device = device)\n",
    "        fake_images =generator(noise, embeddings)\n",
    "        real_out, real_act = discriminator(images, embeddings)\n",
    "        d_loss_real =criterion(real_out, torch.full_like(real_out, real_label, device=device))\n",
    "        wrong_out, wrong_act = discriminator(wrong_images, embeddings)\n",
    "        d_loss_wrong =criterion(wrong_out. torch.full_like(wrong_out. fake_label, device=device))\n",
    "        fake_out, fake_act = discriminator(fake_images.detach(), embeddings)\n",
    "        d_loss_fake =criterion(fake_out, torch.full_like(fake_out, fake_label, device =device))\n",
    "        d_loss = d_loss_real +d_loss_wrong+d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_discriminarator.step()\n",
    "        optimizer_generator.zero_grad()\n",
    "        noise = torch.randn(batch_size, noise_dimension, 1,1)\n",
    "        fake_images = generator(noise, embeddings)\n",
    "        out_fake, act_fake = discriminator(fake_images, embeddings)\n",
    "        out_real, act_real = discriminator(images, embeddings)\n",
    "        g_cbe = criterion(out_fake, torch.full_like(out_fake, real_label, device=device))\n",
    "        gl1 = l1_coefficient *l1_loss(fake_images, images)\n",
    "        gl2 = l2_loss(torch.mean(act_fake, 0), torch.mean(act_real, 0).detach())\n",
    "\n",
    "        g_loss = g_cbe + gl1+gl2\n",
    "        g_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "        D_losses.append(d_loss.item())\n",
    "        G_losses.append(g_loss.item())\n",
    "        if (batch_index+1)% log_interval ==0 and batch_index>0:\n",
    "            print('Epoch {} [{}/{}] loss_discriminator: {: .4f} loss_genarator: {: .4f} time:{: .2f}'.format(\n",
    "                epoch+1, batch_index+1, len(train_loader),\n",
    "                d_loss.mean().item(),g_loss.mean().iteam(), time.time()-batch_time\n",
    "            ))\n",
    "        if batch_index == len(train_loader) -1 and ((epoch+1)%10 ==0 or epoch ==0):\n",
    "            viz_sample = torch.cat((images[:32], fake_images[:32],0))\n",
    "            vutils.save_image(viz_sample, os.path.join(output_save_path, \"output_{}_epoch_{}.png\".fromat(date, epoch+1)), nrow =8, normalize =True)\n",
    "        torch.save(generator.state_dict(), os.path.join(model_save_path, 'generator_{}.pth'.format(date)))\n",
    "        torch.save(discriminator.state_dict(), os.path.join(model_save_path, 'discriminator_{}.pth'.format(date)))\n",
    "        print('Total train time: {: .2f}'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator Loss during Training\")\n",
    "plt.plot(G_losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(output_save_path, 'output_geenration_Loss_{}.png').fromat(date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator loss plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Discriminator Loss During Training\")\n",
    "plt.plot(D_losses)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(os.path.join(output_save_path, 'output_discriminatorLoss_{}.png'.format(date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all file names from the \"generated_images\" directory\n",
    "file_names = os.listdir(output_save_path)\n",
    "file_names = [name for name in file_names if name.startswith('output_{}_'.format(date))]\n",
    "\n",
    "# Sort the file names numerically\n",
    "file_names = sorted(file_names, key=lambda name: int(name.split('_')[3].split('.')[0]))\n",
    "\n",
    "# Create a list to store the read images\n",
    "images = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    images.append(imageio.imread(os.path.join(output_save_path,file_name)))\n",
    "\n",
    "imageio.mimsave(os.path.join(output_save_path, 'output_gif_{}.gif'.format(date)), images, fps=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Load the GIF\n",
    "with open(os.path.join(output_save_path, 'output_gif_{}.gif'.format(date)),'rb') as file:\n",
    "    display(Image(file.read()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
